{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e867592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---- import your metric ----\n",
    "from kaggle_evaluation import score as competition_score\n",
    "try:\n",
    "    from kaggle_evaluation import ParticipantVisibleError\n",
    "except Exception:\n",
    "    class ParticipantVisibleError(Exception): ...\n",
    "\n",
    "\n",
    "\n",
    "def to_allocation(preds: np.ndarray, k: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Sigmoid mapping to [0,2]. k is tuned on validation.\n",
    "    \"\"\"\n",
    "    return np.clip(2.0 * (1.0 / (1.0 + np.exp(-preds * k))), 0.0, 2.0)\n",
    "\n",
    "\n",
    "def eval_with_metric(solution_pl: pl.DataFrame, allocations: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Wrap kaggle_evaluation.score:\n",
    "      score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float\n",
    "    We pass 'date_id' to match the signature.\n",
    "    \"\"\"\n",
    "    sol_pd = solution_pl.select([\"date_id\", \"forward_returns\", \"risk_free_rate\"]).to_pandas().copy()\n",
    "    sub_pd = pd.DataFrame({\n",
    "        \"date_id\": sol_pd[\"date_id\"].values,  # not used inside score(), but required by its signature\n",
    "        \"prediction\": allocations\n",
    "    })\n",
    "    try:\n",
    "        return float(competition_score(sol_pd, sub_pd, row_id_column_name=\"date_id\"))\n",
    "    except ParticipantVisibleError as e:\n",
    "        # Metric guards (e.g., bounds, zero std): treat as poor score\n",
    "        # You can print the warning if desired.\n",
    "        # print(f\"[metric warning] {e}\")\n",
    "        return -1e9\n",
    "\n",
    "\n",
    "def tune_k_on_val(val_df: pl.DataFrame, raw_preds: np.ndarray) -> tuple[float, float]:\n",
    "    grid = [5, 10, 20, 40, 80, 120]\n",
    "    best_score, best_k = -1e9, grid[0]\n",
    "    for k in grid:\n",
    "        alloc = to_allocation(raw_preds, k)\n",
    "        score = eval_with_metric(val_df, alloc)\n",
    "        if score > best_score:\n",
    "            best_score, best_k = score, k\n",
    "    return best_k, best_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MAX_LAG = 5\n",
    "ROLL_WINDOWS = [10, 30]\n",
    "MAX_ROLL = max(ROLL_WINDOWS)\n",
    "FE_HISTORY = MAX_ROLL + MAX_LAG + 5  # cushion\n",
    "\n",
    "SPECIAL_COLS = {\"date_id\", \"forward_returns\", \"risk_free_rate\", \"target\", \"is_scored\"}\n",
    "\n",
    "def create_features(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Past-only features:\n",
    "      - Lags 1,3,5\n",
    "      - Rolling mean/std (10,30) with shift(1) to avoid using current value.\n",
    "    We do NOT drop rows; XGB handles NaNs.\n",
    "    \"\"\"\n",
    "    features_to_engineer = [c for c in df.columns if c not in SPECIAL_COLS]\n",
    "    out = df.clone()\n",
    "\n",
    "    for feature in features_to_engineer:\n",
    "        # lags\n",
    "        for lag in [1, 3, 5]:\n",
    "            out = out.with_columns(\n",
    "                pl.col(feature).shift(lag).alias(f'{feature}_lag_{lag}')\n",
    "            )\n",
    "        # rolling (shifted to avoid leakage)\n",
    "        for w in ROLL_WINDOWS:\n",
    "            out = out.with_columns(\n",
    "                pl.col(feature).rolling_mean(w).shift(1).alias(f'{feature}_roll_mean_{w}'),\n",
    "                pl.col(feature).rolling_std(w).shift(1).alias(f'{feature}_roll_std_{w}')\n",
    "            )\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Loading training and test data...\")\n",
    "train_path = \"train.csv\"\n",
    "test_path  = \"test.csv\"\n",
    "\n",
    "full_train_df = pl.read_csv(train_path)\n",
    "test_df       = pl.read_csv(test_path)\n",
    "\n",
    "# rename target (we predict market_forward_excess_returns)\n",
    "full_train_df = full_train_df.rename({\"market_forward_excess_returns\": \"target\"})\n",
    "\n",
    "# Cast numeric columns to Float64 (except date_id)\n",
    "num_cols = [c for c in full_train_df.columns if c != \"date_id\"]\n",
    "full_train_df = full_train_df.with_columns(pl.col(num_cols).cast(pl.Float64, strict=False))\n",
    "\n",
    "print(\"Engineering features on training set...\")\n",
    "processed_df = create_features(full_train_df)\n",
    "\n",
    "# FEATURES (exclude specials + date_id)\n",
    "FEATURES = [c for c in processed_df.columns if c not in SPECIAL_COLS and c != \"date_id\"]\n",
    "TARGET_COL = \"target\"\n",
    "\n",
    "\n",
    "\n",
    "# Use last 252 days as primary validation.\n",
    "# Optionally evaluate across last 3 blocks (3 x 252) to reduce regime overfit.\n",
    "VALID_BLOCK = 252\n",
    "USE_MULTI_BLOCK = True  # set False to tune on last block only\n",
    "\n",
    "def get_blocks(df_proc: pl.DataFrame):\n",
    "    N = df_proc.height\n",
    "    if USE_MULTI_BLOCK and N >= 3 * VALID_BLOCK + 1000:\n",
    "        # Train on everything before each block, evaluate on that block, average score\n",
    "        blocks = []\n",
    "        for m in [3, 2, 1]:\n",
    "            val_end = N - (m-1) * VALID_BLOCK\n",
    "            val_start = val_end - VALID_BLOCK\n",
    "            tr_end = val_start  # train up to start of this val block\n",
    "            blocks.append({\n",
    "                \"train_slice\": (0, tr_end),\n",
    "                \"val_slice\":   (val_start, val_end),\n",
    "            })\n",
    "        return blocks\n",
    "    else:\n",
    "        # Single last block\n",
    "        return [{\n",
    "            \"train_slice\": (0, N - VALID_BLOCK),\n",
    "            \"val_slice\":   (N - VALID_BLOCK, N),\n",
    "        }]\n",
    "\n",
    "VAL_BLOCKS = get_blocks(processed_df)\n",
    "\n",
    "def slice_np(df_proc: pl.DataFrame, feature_cols, target_col, start, end):\n",
    "    X = df_proc.slice(start, end - start).select(feature_cols).to_numpy()\n",
    "    y = df_proc.slice(start, end - start).select(target_col).to_numpy().ravel()\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "def trial_to_params(trial: optuna.Trial):\n",
    "    return dict(\n",
    "        objective='reg:squarederror',\n",
    "        tree_method='hist',\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        # search space (tight to avoid overfit to one year)\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 400, 900),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 0.02, 0.15, log=True),\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 3, 8),\n",
    "        subsample=trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        reg_alpha=trial.suggest_float(\"reg_alpha\", 0.0, 3.0),\n",
    "        reg_lambda=trial.suggest_float(\"reg_lambda\", 0.0, 3.0),\n",
    "    )\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    params = trial_to_params(trial)\n",
    "\n",
    "    scores = []\n",
    "    for blk in VAL_BLOCKS:\n",
    "        tr_s, tr_e = blk[\"train_slice\"]\n",
    "        va_s, va_e = blk[\"val_slice\"]\n",
    "\n",
    "        X_tr, y_tr = slice_np(processed_df, FEATURES, TARGET_COL, tr_s, tr_e)\n",
    "        X_va, y_va = slice_np(processed_df, FEATURES, TARGET_COL, va_s, va_e)\n",
    "\n",
    "        # Fit model on this block's train\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model.fit(X_tr, y_tr, verbose=False)\n",
    "\n",
    "        # Predict on this block's val\n",
    "        raw_preds = model.predict(X_va)\n",
    "\n",
    "        # Build a minimal solution DF for metric (date_id + fwd + rf) over val slice\n",
    "        sol_va = processed_df.slice(va_s, va_e - va_s).select([\"date_id\", \"forward_returns\", \"risk_free_rate\"])\n",
    "\n",
    "        # Tune k on this block and collect the score\n",
    "        best_k, best_score = tune_k_on_val(sol_va, raw_preds)\n",
    "        scores.append(best_score)\n",
    "\n",
    "    # Average across blocks (or single block)\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "# Run Optuna\n",
    "N_TRIALS = 30  # keep modest to reduce overfit and runtime\n",
    "print(f\"Starting Optuna tuning... (trials={N_TRIALS}, multi_block={USE_MULTI_BLOCK})\")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "best_params = trial_to_params(study.best_trial)\n",
    "print(\"Best Optuna params:\", {k: v for k, v in best_params.items() if k not in [\"objective\", \"tree_method\", \"n_jobs\", \"random_state\"]})\n",
    "\n",
    "# For reporting: compute best k on the final block using best params\n",
    "last_blk = VAL_BLOCKS[-1]\n",
    "tr_s, tr_e = last_blk[\"train_slice\"]\n",
    "va_s, va_e = last_blk[\"val_slice\"]\n",
    "X_tr, y_tr = slice_np(processed_df, FEATURES, TARGET_COL, tr_s, tr_e)\n",
    "X_va, y_va = slice_np(processed_df, FEATURES, TARGET_COL, va_s, va_e)\n",
    "tmp_model = xgb.XGBRegressor(**best_params)\n",
    "tmp_model.fit(X_tr, y_tr, verbose=False)\n",
    "raw_val_preds = tmp_model.predict(X_va)\n",
    "best_k_final, val_score_final = tune_k_on_val(\n",
    "    processed_df.slice(va_s, va_e - va_s).select([\"date_id\", \"forward_returns\", \"risk_free_rate\"]),\n",
    "    raw_val_preds\n",
    ")\n",
    "print(f\"Tuned k on validation (final block): best_k={best_k_final}, val_score={val_score_final:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "X_full = processed_df.select(FEATURES).to_numpy()\n",
    "y_full = processed_df.select(TARGET_COL).to_numpy().ravel()\n",
    "print(f\"Refitting on full dataset: {X_full.shape[0]} rows...\")\n",
    "final_model = xgb.XGBRegressor(**best_params)\n",
    "final_model.fit(X_full, y_full, verbose=False)\n",
    "print(\"Final model trained.\")\n",
    "\n",
    "# Prepare history for test walk\n",
    "HISTORY_BUFFER = full_train_df.tail(FE_HISTORY).clone()\n",
    "print(f\"Prepared HISTORY_BUFFER with last {FE_HISTORY} raw rows.\")\n",
    "print(f\"FEATURES count: {len(FEATURES)} | BEST_K: {best_k_final}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Generating predictions on test.csv ...\")\n",
    "\n",
    "# Standardize incoming test column names (match training schema)\n",
    "rename_map = {\n",
    "    'lagged_forward_returns': 'forward_returns',\n",
    "    'lagged_risk_free_rate': 'risk_free_rate',\n",
    "    'lagged_market_forward_excess_returns': 'target'\n",
    "}\n",
    "\n",
    "# Cast test floats\n",
    "float_cols_test = [c for c in test_df.columns if c != \"date_id\"]\n",
    "test_df = test_df.with_columns(pl.col(float_cols_test).cast(pl.Float64, strict=False))\n",
    "\n",
    "allocations = []\n",
    "date_ids = []\n",
    "\n",
    "for i in range(test_df.height):\n",
    "    row = test_df.slice(i, 1)\n",
    "\n",
    "    # Standardize names for the incoming row\n",
    "    row = row.rename({k: v for k, v in rename_map.items() if k in row.columns})\n",
    "\n",
    "    # Drop runtime-only column if present\n",
    "    if 'is_scored' in row.columns:\n",
    "        row = row.drop('is_scored')\n",
    "\n",
    "    # Append, keep tail for FE\n",
    "    HISTORY_BUFFER = pl.concat([HISTORY_BUFFER, row], how=\"vertical\").tail(FE_HISTORY)\n",
    "\n",
    "    # Feature engineering on tail\n",
    "    feat_tail = create_features(HISTORY_BUFFER)\n",
    "\n",
    "    # Latest engineered row â†’ select FEATURES\n",
    "    latest = feat_tail.tail(1)\n",
    "    latest_pd = latest.select(FEATURES).to_pandas()\n",
    "\n",
    "    # Ensure all training FEATURES exist\n",
    "    for c in FEATURES:\n",
    "        if c not in latest_pd.columns:\n",
    "            latest_pd[c] = 0.0\n",
    "    latest_pd = latest_pd[FEATURES]\n",
    "\n",
    "    # Predict and map to allocation\n",
    "    raw_pred = float(final_model.predict(latest_pd.values)[0])\n",
    "    alloc = float(to_allocation(np.array([raw_pred]), best_k_final)[0])\n",
    "\n",
    "    allocations.append(alloc)\n",
    "    date_ids.append(int(row['date_id'][0]))\n",
    "\n",
    "# Save submission (your local scorer expects 'prediction')\n",
    "submission = pd.DataFrame({\n",
    "    'date_id': date_ids,\n",
    "    'prediction': allocations\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Saved submission.csv (columns: date_id, prediction)\")\n",
    "\n",
    "\n",
    "\n",
    "val_alloc = to_allocation(raw_val_preds, best_k_final)\n",
    "val_score_check = eval_with_metric(\n",
    "    processed_df.slice(va_s, va_e - va_s).select([\"date_id\", \"forward_returns\", \"risk_free_rate\"]),\n",
    "    val_alloc\n",
    ")\n",
    "print(f\"Validation metric (final block, best params): {val_score_check:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
